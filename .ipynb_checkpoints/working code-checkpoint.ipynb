{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('sample30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                          0\n",
      "brand                       0\n",
      "categories                  0\n",
      "manufacturer              141\n",
      "name                        0\n",
      "reviews_date               46\n",
      "reviews_didPurchase     14068\n",
      "reviews_doRecommend      2570\n",
      "reviews_rating              0\n",
      "reviews_text                0\n",
      "reviews_title             190\n",
      "reviews_userCity        28071\n",
      "reviews_userProvince    29830\n",
      "reviews_username           63\n",
      "user_sentiment              1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                       0.00\n",
      "brand                    0.00\n",
      "categories               0.00\n",
      "manufacturer             0.47\n",
      "name                     0.00\n",
      "reviews_date             0.15\n",
      "reviews_didPurchase     46.89\n",
      "reviews_doRecommend      8.57\n",
      "reviews_rating           0.00\n",
      "reviews_text             0.00\n",
      "reviews_title            0.63\n",
      "reviews_userCity        93.57\n",
      "reviews_userProvince    99.43\n",
      "reviews_username         0.21\n",
      "user_sentiment           0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().mean().round(4) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(columns=['reviews_didPurchase','reviews_doRecommend','reviews_userCity','reviews_userProvince'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  0.00\n",
      "brand               0.00\n",
      "categories          0.00\n",
      "manufacturer        0.47\n",
      "name                0.00\n",
      "reviews_date        0.15\n",
      "reviews_rating      0.00\n",
      "reviews_text        0.00\n",
      "reviews_title       0.63\n",
      "reviews_username    0.21\n",
      "user_sentiment      0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().mean().round(4) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['reviews_text'].notna()]\n",
    "df = df[df['reviews_title'].notna()]\n",
    "df = df[df['reviews_username'].notna()]\n",
    "df = df[df['user_sentiment'].notna()]\n",
    "df = df[df['reviews_date'].notna()]\n",
    "df = df[df['manufacturer'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  0.0\n",
      "brand               0.0\n",
      "categories          0.0\n",
      "manufacturer        0.0\n",
      "name                0.0\n",
      "reviews_date        0.0\n",
      "reviews_rating      0.0\n",
      "reviews_text        0.0\n",
      "reviews_title       0.0\n",
      "reviews_username    0.0\n",
      "user_sentiment      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().mean().round(4) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i love this album. it's very good. more to the...\n",
       "1        Good flavor. This review was collected as part...\n",
       "2                                             Good flavor.\n",
       "3        I read through the reviews on here before look...\n",
       "4        My husband bought this gel for us. The gel cau...\n",
       "                               ...                        \n",
       "29995    I got this conditioner with Influenster to try...\n",
       "29996    I love it , I received this for review purpose...\n",
       "29997    First of all I love the smell of this product....\n",
       "29998    I received this through Influenster and will n...\n",
       "29999    I received this product complimentary from inf...\n",
       "Name: reviews_text, Length: 29566, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviews_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    26262\n",
       "Negative     3304\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imbalanced reviews i.e. Positive reviews are more than Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews(df,column):\n",
    "    df[column]=df[column].str.lower() # convert everything to lower\n",
    "    df[column]=df[column].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")# remove punctuation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviews_text.head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_reviews(df,'reviews_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_pos_tag']=df.reviews_text.apply(lambda x:  nltk.pos_tag(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(i, RB), (love, VBP), (this, DT), (album, NN)...\n",
       "1    [(good, JJ), (flavor, NN), (this, DT), (review...\n",
       "2                           [(good, JJ), (flavor, NN)]\n",
       "3    [(i, NN), (read, VBP), (through, IN), (the, DT...\n",
       "4    [(my, PRP$), (husband, NN), (bought, VBD), (th...\n",
       "Name: reviews_pos_tag, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_pos_tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLemmatizedTokens(word_with_tag_list):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens= set([lemmatizer.lemmatize(word,get_wordnet_pos(tag)) for (word,tag) in word_with_tag_list if word not in stop_words ])\n",
    "    return \" \".join(tokens)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df.reviews_pos_tag.apply(lambda x: getLemmatizedTokens(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    26262\n",
       "Negative     3304\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_sentiment']=df['user_sentiment'].apply(lambda x : 1 if x=='Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26262\n",
       "0     3304\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['review'] \n",
    "y=df['user_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    current rating hop ! way hype 5star hip everyd...\n",
       "1            part flavor review collect promotion good\n",
       "2                                          flavor good\n",
       "3    much look pleasant less starter live sensation...\n",
       "4    irritation felt cause buy skin like n't gel re...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26262\n",
       "0     3304\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 50 \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',    # Remove accents and perform other character normalization during the preprocessing step. \n",
    "    analyzer='word',            # Whether the feature should be made of word or character n-grams.\n",
    "    token_pattern=r'\\w{1,}',    # Regular expression denoting what constitutes a “token”, only used if analyzer == 'word'\n",
    "    ngram_range=(1, 3),         # The lower and upper boundary of the range of n-values for different n-grams to be extracted\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True)\n",
    "\n",
    "word_vectorizer.fit(X_train)    # Fiting it on Train\n",
    "train_word_features = word_vectorizer.transform(X_train)  # Transform on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = word_vectorizer.transform(X_train.tolist())\n",
    "X_test_transformed = word_vectorizer.transform(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train= logit.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = logit.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy 0.8917700112739572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.85      0.12        74\n",
      "           1       1.00      0.89      0.94      8796\n",
      "\n",
      "    accuracy                           0.89      8870\n",
      "   macro avg       0.53      0.87      0.53      8870\n",
      "weighted avg       0.99      0.89      0.94      8870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression accuracy\", accuracy_score(y_pred_test, y_test))\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=metrics.confusion_matrix(y_train, y_pred_train)\n",
    "cm_test=metrics.confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  206,  2086],\n",
       "       [    3, 18401]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  63,  949],\n",
       "       [  11, 7847]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "TN_tr = cm_train[0, 0] \n",
    "FP_tr = cm_train[0, 1]\n",
    "FN_tr = cm_train[1, 0]\n",
    "TP_tr = cm_train[1, 1]\n",
    "\n",
    "#test set\n",
    "TN = cm_test[0, 0]\n",
    "FP = cm_test[0, 1]\n",
    "FN = cm_test[1, 0]\n",
    "TP = cm_test[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity for train set:  0.9998369919582699\n",
      "sensitivity for test set:  0.9986001527106134\n"
     ]
    }
   ],
   "source": [
    "sensitivity_tr = TP_tr / float(FN_tr + TP_tr)\n",
    "print(\"sensitivity for train set: \",sensitivity_tr)\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity for test set: \",sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity for train set:  0.08987783595113438\n",
      "specificity for test set:  0.06225296442687747\n"
     ]
    }
   ],
   "source": [
    "specificity_tr = TN_tr / float(TN_tr + FP_tr)\n",
    "print(\"specificity for train set: \",specificity_tr)\n",
    "specificity = TN / float(TN + FP)\n",
    "print(\"specificity for test set: \",specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Logistic regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train).iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = word_vectorizer.transform(X_train)\n",
    "X_test_transformed = word_vectorizer.transform(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({1: 18381, 0: 2315})\n",
      "After Counter({1: 18381, 0: 18381})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print('Before',counter)\n",
    "\n",
    "# oversampling the train dataset using SMOTE\n",
    "smt = SMOTE()\n",
    "X_train_transformed, y_train = smt.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train= logit.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = logit.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy 0.8989853438556934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.53      0.63      1413\n",
      "           1       0.92      0.97      0.94      7457\n",
      "\n",
      "    accuracy                           0.90      8870\n",
      "   macro avg       0.84      0.75      0.78      8870\n",
      "weighted avg       0.89      0.90      0.89      8870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression accuracy\", accuracy_score(y_pred_test, y_test))\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=metrics.confusion_matrix(y_train, y_pred_train)\n",
    "cm_test=metrics.confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "TN_tr = cm_train[0, 0] \n",
    "FP_tr = cm_train[0, 1]\n",
    "FN_tr = cm_train[1, 0]\n",
    "TP_tr = cm_train[1, 1]\n",
    "\n",
    "#test set\n",
    "TN = cm_test[0, 0]\n",
    "FP = cm_test[0, 1]\n",
    "FN = cm_test[1, 0]\n",
    "TP = cm_test[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity for train set:  0.9625156411511887\n",
      "sensitivity for test set:  0.9162542824514656\n"
     ]
    }
   ],
   "source": [
    "sensitivity_tr = TP_tr / float(FN_tr + TP_tr)\n",
    "print(\"sensitivity for train set: \",sensitivity_tr)\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity for test set: \",sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity for train set:  0.9961917197105707\n",
      "specificity for test set:  0.7613751263902933\n"
     ]
    }
   ],
   "source": [
    "specificity_tr = TN_tr / float(TN_tr + FP_tr)\n",
    "print(\"specificity for train set: \",specificity_tr)\n",
    "specificity = TN / float(TN + FP)\n",
    "print(\"specificity for test set: \",specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=50, random_state=seed, n_jobs=-1)\n",
    "classifier.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train= classifier.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test= classifier.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy 0.9062006764374295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.60      0.53       781\n",
      "           1       0.96      0.94      0.95      8089\n",
      "\n",
      "    accuracy                           0.91      8870\n",
      "   macro avg       0.72      0.77      0.74      8870\n",
      "weighted avg       0.92      0.91      0.91      8870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest accuracy\", accuracy_score(y_pred_test, y_test))\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=metrics.confusion_matrix(y_train, y_pred_train)\n",
    "cm_test=metrics.confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "TN_tr = cm_train[0, 0] \n",
    "FP_tr = cm_train[0, 1]\n",
    "FN_tr = cm_train[1, 0]\n",
    "TP_tr = cm_train[1, 1]\n",
    "\n",
    "#test set\n",
    "TN = cm_test[0, 0]\n",
    "FP = cm_test[0, 1]\n",
    "FN = cm_test[1, 0]\n",
    "TP = cm_test[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity for train set:  0.9995103639627877\n",
      "sensitivity for test set:  0.9604111153406928\n"
     ]
    }
   ],
   "source": [
    "sensitivity_tr = TP_tr / float(FN_tr + TP_tr)\n",
    "print(\"sensitivity for train set: \",sensitivity_tr)\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity for test set: \",sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity for train set:  0.9999455959958653\n",
      "specificity for test set:  0.474216380182002\n"
     ]
    }
   ],
   "source": [
    "specificity_tr = TN_tr / float(TN_tr + FP_tr)\n",
    "print(\"specificity for train set: \",specificity_tr)\n",
    "specificity = TN / float(TN + FP)\n",
    "print(\"specificity for test set: \",specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mouni\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:09:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBClassifier(n_jobs=-1)\n",
    "xgb.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train= xgb.predict(X_train_transformed)\n",
    "y_pred_test= xgb.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"xgboost accuracy\", accuracy_score(y_pred_test, y_test))\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=metrics.confusion_matrix(y_train, y_pred_train)\n",
    "cm_test=metrics.confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "TN_tr = cm_train[0, 0] \n",
    "FP_tr = cm_train[0, 1]\n",
    "FN_tr = cm_train[1, 0]\n",
    "TP_tr = cm_train[1, 1]\n",
    "\n",
    "#test set\n",
    "TN = cm_test[0, 0]\n",
    "FP = cm_test[0, 1]\n",
    "FN = cm_test[1, 0]\n",
    "TP = cm_test[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_tr = TP_tr / float(FN_tr + TP_tr)\n",
    "print(\"sensitivity for train set: \",sensitivity_tr)\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity for test set: \",sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_tr = TN_tr / float(TN_tr + FP_tr)\n",
    "print(\"specificity for train set: \",specificity_tr)\n",
    "specificity = TN / float(TN + FP)\n",
    "print(\"specificity for test set: \",specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "# Building Random Forest Model.\n",
    "time1 = time.time()\n",
    "\n",
    "n_estimators = [10,20,30] \n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [4,5,6]\n",
    "max_depth.append(None) # If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_final = RandomizedSearchCV(estimator=rf_classifier, param_distributions=random_grid, n_iter=5, cv=3, \n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "rf_final.fit(X_train_transformed,y_train)\n",
    "\n",
    "time_taken = time.time() - time1\n",
    "print('Time Taken: {:.2f} seconds'.format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train= rf_final.predict(X_train_transformed)\n",
    "y_pred_test= rf_final.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "TN_tr = cm_train[0, 0] \n",
    "FP_tr = cm_train[0, 1]\n",
    "FN_tr = cm_train[1, 0]\n",
    "TP_tr = cm_train[1, 1]\n",
    "\n",
    "#test set\n",
    "TN = cm_test[0, 0]\n",
    "FP = cm_test[0, 1]\n",
    "FN = cm_test[1, 0]\n",
    "TP = cm_test[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_tr = TP_tr / float(FN_tr + TP_tr)\n",
    "print(\"sensitivity for train set: \",sensitivity_tr)\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity for test set: \",sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_tr = TN_tr / float(TN_tr + FP_tr)\n",
    "print(\"specificity for train set: \",specificity_tr)\n",
    "specificity = TN / float(TN + FP)\n",
    "print(\"specificity for test set: \",specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[[\"reviews_username\",\"reviews_rating\",\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df1, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = train.pivot_table(\n",
    "    index='reviews_username',\n",
    "    columns='name',\n",
    "    values='reviews_rating'\n",
    ").fillna(0)\n",
    "\n",
    "df_pivot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train['reviews_rating'] = dummy_train['reviews_rating'].apply(lambda x: 0 if x>=1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train.reviews_rating.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train = dummy_train.pivot_table(index='reviews_username', columns='name', values='reviews_rating').fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Creating the User Similarity Matrix using pairwise_distance function.\n",
    "user_correlation = 1 - pairwise_distances(df_pivot, metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-movie matrix.\n",
    "df_pivot = train.pivot_table(\n",
    "    index='reviews_username',\n",
    "    columns='name',\n",
    "    values='reviews_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.nanmean(df_pivot, axis=1)\n",
    "user_df_subtracted = (df_pivot.T-mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "user_df_subtracted.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# User Similarity Matrix: The correlation matrix of users.\n",
    "user_correlation = 1 - pairwise_distances(user_df_subtracted.fillna(0), metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation[user_correlation<0]=0\n",
    "user_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_ratings = np.dot(user_correlation, df_pivot.fillna(0))\n",
    "user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_final_rating = np.multiply(user_predicted_ratings,dummy_train)\n",
    "user_final_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item based similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_matrix = train.pivot_table(index='reviews_username', columns='name', values='reviews_rating').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.nanmean(item_based_matrix, axis=1)\n",
    "item_df_subtracted = (item_based_matrix.T-mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_subtracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "item_correlation = 1 - pairwise_distances(item_df_subtracted.fillna(0), metric='cosine')\n",
    "item_correlation[np.isnan(item_correlation)] = 0\n",
    "print(item_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation[item_correlation<0]=0\n",
    "item_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_predicted_ratings = np.dot((item_based_matrix.fillna(0).T),item_correlation)\n",
    "item_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_final_rating = np.multiply(item_predicted_ratings,dummy_train)\n",
    "item_final_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = test[test.reviews_username.isin(train.reviews_username)]\n",
    "common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_based_matrix = common.pivot_table(index='reviews_username', columns='name', values='reviews_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_based_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df = pd.DataFrame(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_subtracted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_subtracted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df['reviews_username'] = user_df_subtracted.index\n",
    "user_correlation_df.set_index('reviews_username',inplace=True)\n",
    "user_correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name = common.reviews_username.tolist()\n",
    "\n",
    "user_correlation_df.columns = user_df_subtracted.index.tolist()\n",
    "user_correlation_df_1 =  user_correlation_df[user_correlation_df.index.isin(list_name)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_2 = user_correlation_df_1.T[user_correlation_df_1.T.index.isin(list_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3 = user_correlation_df_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3[user_correlation_df_3<0]=0\n",
    "\n",
    "common_user_predicted_ratings = np.dot(user_correlation_df_3, common_user_based_matrix.fillna(0))\n",
    "common_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test = common.copy()\n",
    "\n",
    "dummy_test['reviews_rating'] = dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "\n",
    "dummy_test = dummy_test.pivot_table(index='reviews_username', columns='name', values='reviews_rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_predicted_ratings = np.multiply(common_user_predicted_ratings,dummy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_predicted_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import *\n",
    "\n",
    "X  = common_user_predicted_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ = common.pivot_table(index='reviews_username', columns='name', values='reviews_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total non-NaN value\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (sum(sum((common_ - y )**2))/total_non_nan)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common =  test[test.name.isin(train.name)]\n",
    "\n",
    "common.name.nunique()\n",
    "common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item_based_matrix = common.pivot_table(index='reviews_username', columns='name', values='reviews_rating').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item_based_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df = pd.DataFrame(item_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df['reviews_items'] = item_df_subtracted.index\n",
    "item_correlation_df.set_index('reviews_items',inplace=True)\n",
    "item_correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item_based_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name = common.name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df.columns = item_df_subtracted.index.tolist()\n",
    "item_correlation_df_1 =  item_correlation_df[item_correlation_df.index.isin(list_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df_2 = item_correlation_df_1.T[item_correlation_df_1.T.index.isin(list_name)]\n",
    "item_correlation_df_3 = item_correlation_df_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df_3[item_correlation_df_3<0]=0\n",
    "common_item_predicted_ratings = np.dot(item_correlation_df_3, common_item_based_matrix.fillna(0))\n",
    "common_item_predicted_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item_predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test = common.copy()\n",
    "\n",
    "dummy_test['reviews_rating'] = dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "\n",
    "dummy_test = dummy_test.pivot_table(index='reviews_username', columns='name', values='reviews_rating').T.fillna(0)\n",
    "\n",
    "common_item_predicted_ratings = np.multiply(common_item_predicted_ratings,dummy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ = common.pivot_table(index='reviews_username', columns='name', values='reviews_rating').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import *\n",
    "\n",
    "X  = common_item_predicted_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total non-NaN value\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (sum(sum((common_ - y )**2))/total_non_nan)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the respective files Pickle \n",
    "import pickle\n",
    "pickle.dump(user_final_rating,open('user_final_rating.pkl','wb'))\n",
    "user_final_rating =  pickle.load(open('user_final_rating.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using User based similarity system as its RMSE value is less than item based similarity system.\n",
    "user_input = input(\"Enter your user name\")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommending the Top 20 products to the user.\n",
    "d = user_final_rating.loc[user_input].sort_values(ascending=False)[0:20]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the respective files and models through Pickle \n",
    "import pickle\n",
    "pickle.dump(logit,open('logit_model.pkl', 'wb'))\n",
    "# loading pickle object\n",
    "logit =  pickle.load(open('logit_model.pkl', 'rb'))\n",
    "\n",
    "pickle.dump(word_vectorizer,open('word_vectorizer.pkl','wb'))\n",
    "# loading pickle object\n",
    "word_vectorizer = pickle.load(open('word_vectorizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to recommend top 5 filtered products to the user.\n",
    "def recommend(user_input):\n",
    "    d = user_final_rating.loc[user_input].sort_values(ascending=False)[0:20]\n",
    "\n",
    "    # Based on positive sentiment percentage.\n",
    "    i= 0\n",
    "    a = {}\n",
    "    for prod_name in d.index.tolist():\n",
    "      product_name = prod_name\n",
    "      product_name_review_list =df[df['name']== product_name]['review'].tolist()\n",
    "      features= word_vectorizer.transform(product_name_review_list)\n",
    "      logit.predict(features)\n",
    "      a[product_name] = logit.predict(features).mean()*100\n",
    "    b= pd.Series(a).sort_values(ascending = False).head(5).index.tolist()\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
